{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"E:/Project/ZLTProgram/CelebA\")\n",
    "from Utils.InceptionV3 import InceptionV3\n",
    "from Utils.dataload import CELEBA,CELEBA_GEN\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "root='E:/Project/ModelAndDataset/data'\n",
    "attr_name='Smiling'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model=InceptionV3()\n",
    "model=model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "Load Test dataset: 60780\n",
      "Load images from: E:\\Project\\ModelAndDataset\\data\\celebA\\Gen\\cVAEGAN\\Smiling_image.npy\n",
      "Load labels from: E:\\Project\\ModelAndDataset\\data\\celebA\\Gen\\cVAEGAN\\Smiling_label.npy\n",
      "Load images from: E:\\Project\\ModelAndDataset\\data\\celebA\\Gen\\cVAEGAN_Advanced_V2\\Smiling_image.npy\n",
      "Load labels from: E:\\Project\\ModelAndDataset\\data\\celebA\\Gen\\cVAEGAN_Advanced_V2\\Smiling_label.npy\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:\\\\Project\\\\ModelAndDataset\\\\data\\\\celebA\\\\Gen\\\\cVAEGAN_Advanced_V2\\\\Smiling_image.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 20\u001b[0m\n\u001b[0;32m     15\u001b[0m genDataset1 \u001b[38;5;241m=\u001b[39m CELEBA_GEN(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProject\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mModelAndDataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcelebA\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGen\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcVAEGAN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m                         attr_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSmiling\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     17\u001b[0m                         transform\u001b[38;5;241m=\u001b[39mtransform\n\u001b[0;32m     18\u001b[0m                         )\n\u001b[0;32m     19\u001b[0m genLoader1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(genDataset1,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 20\u001b[0m genDataset2 \u001b[38;5;241m=\u001b[39m \u001b[43mCELEBA_GEN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mE:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mProject\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mModelAndDataset\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mcelebA\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mGen\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mcVAEGAN_Advanced_V2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mattr_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSmiling\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m genLoader2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(genDataset2,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32me:\\Project\\ZLTProgram\\CelebA\\Utils\\dataload.py:28\u001b[0m, in \u001b[0;36mCELEBA_GEN.__init__\u001b[1;34m(self, root, attr_name, transform)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoad images from:\u001b[39m\u001b[38;5;124m'\u001b[39m,img_load_path)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoad labels from:\u001b[39m\u001b[38;5;124m'\u001b[39m,label_load_path)\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_load_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mload(label_load_path)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\AdversarialSampleDetection\\lib\\site-packages\\numpy\\lib\\npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:\\\\Project\\\\ModelAndDataset\\\\data\\\\celebA\\\\Gen\\\\cVAEGAN_Advanced_V2\\\\Smiling_image.npy'"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "# realDataset=CELEBA_GEN(root=\"E:/Project/ModelAndDataset/data/celebA/Gen/real\",\n",
    "#                         attr_name='Smiling',\n",
    "#                         transform=transform\n",
    "#                         )\n",
    "realDataset=CELEBA(root=root,train=False,train_ratio=0.7,transform=transform,label=attr_name)\n",
    "realLoader = torch.utils.data.DataLoader(realDataset,batch_size=64,shuffle=False)\n",
    "# genDataset1 = CELEBA_GEN(root=\"E:\\Project\\ModelAndDataset\\data\\celebA\\Gen\\cVAEGAN_AdvancedV2\",\n",
    "#                         attr_name='Smiling',\n",
    "#                         transform=transform\n",
    "#                         )\n",
    "# genLoader1 = torch.utils.data.DataLoader(genDataset1,batch_size=64,shuffle=False)\n",
    "\n",
    "\n",
    "genDataset1 = CELEBA_GEN(root=\"E:\\Project\\ModelAndDataset\\data\\celebA\\Gen\\cVAEGAN\",\n",
    "                        attr_name='Smiling',\n",
    "                        transform=transform\n",
    "                        )\n",
    "genLoader1 = torch.utils.data.DataLoader(genDataset1,batch_size=64,shuffle=False)\n",
    "genDataset2 = CELEBA_GEN(root=\"E:\\Project\\ModelAndDataset\\data\\celebA\\Gen\\cVAEGAN_Advanced_V2\",\n",
    "                        attr_name='Smiling',\n",
    "                        transform=transform\n",
    "                        )\n",
    "genLoader2 = torch.utils.data.DataLoader(genDataset2,batch_size=64,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid: 61.41494330227158\n"
     ]
    }
   ],
   "source": [
    "from Utils.EvaluatingTools import calculate_fid,calculate_ssim,calculate_l2_distance,DrawEvaluteResult\n",
    "fid1=calculate_fid(raw_dataloader=realLoader,\n",
    "                gen_dataloader=genLoader1,\n",
    "                model=model,\n",
    "                batch_nums=150,\n",
    "                batch_size=64,\n",
    "                device=device,\n",
    "                dims=2048\n",
    "                )\n",
    "print(\"fid:\",fid1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid 27.94372425430288\n"
     ]
    }
   ],
   "source": [
    "fid2=calculate_fid(raw_dataloader=realLoader,\n",
    "                gen_dataloader=genLoader2,\n",
    "                model=model,\n",
    "                batch_nums=150,\n",
    "                batch_size=64,\n",
    "                device=device,\n",
    "                dims=2048\n",
    "                )\n",
    "print(\"fid\",fid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim1=calculate_ssim(raw_dataloader=realLoader,\n",
    "                     gen_dataloader=genLoader1,\n",
    "                     batch_nums=150\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim2=calculate_ssim(raw_dataloader=realLoader,\n",
    "                     gen_dataloader=genLoader2,\n",
    "                     batch_nums=150\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_distance1=calculate_l2_distance(raw_dataloader=realLoader,\n",
    "                                    gen_dataloader=genLoader1,\n",
    "                                    batch_nums=150\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_distance2=calculate_l2_distance(raw_dataloader=realLoader,\n",
    "                                    gen_dataloader=genLoader2,\n",
    "                                    batch_nums=150\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "fig_ssim=DrawEvaluteResult(ssim1,\"original\",ssim2,\"improved\",\"SSIM\",\"number\",\"ssim_value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_l2=DrawEvaluteResult(l2_distance1,\"original\",l2_distance2,\"improved\",\"L2_distance\",\"number\",\"l2_distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(len(ssim1)):\n",
    "    if ssim1[i]>ssim2[i]:\n",
    "        count+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(len(l2_distance1)):\n",
    "    if l2_distance1[i]<l2_distance2[i]:\n",
    "        count+=1\n",
    "count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AdversarialSampleDetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
