{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch.autograd\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Subset\n",
    "from cVAE_GAN_cifar10 import Encoder_cifar10,Decoder_cifar10,Discriminator_cifar10,loss_function\n",
    "# 创建文件夹\n",
    "if not os.path.exists('./img_CVAE-GAN_Cifar10'):\n",
    "    os.mkdir('./img_CVAE-GAN_Cifar10')\n",
    "# GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "batch_size =64\n",
    "num_epoch = 20\n",
    "z_dimension=80\n",
    "\n",
    "img_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "cifar10 = datasets.CIFAR10(\n",
    "    root=\"E:/Project/ModelAndDataset/data\", train=True, transform=img_transform, download=True\n",
    ")\n",
    "# 创建一个包含前6400张图像的子集\n",
    "subset_indices = range(12800)  # 选择所需数量的图像\n",
    "dataset = Subset(cifar10, subset_indices)\n",
    "\n",
    "# data loader 数据载入\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "# 初始化变分自编码器，分类器与判别器\n",
    "encoder=Encoder_cifar10(device=device)\n",
    "decoder=Decoder_cifar10(device=device)\n",
    "discriminator=Discriminator_cifar10(device=device)\n",
    "\n",
    "if not os.path.exists('./img_CVAE-GAN_Cifar10'):\n",
    "        os.mkdir('./img_CVAE-GAN_Cifar10')\n",
    "cudnn.benchmark=True\n",
    "\n",
    "# 初始化优化器\n",
    "optimizer_encoder = optim.Adam(encoder.parameters(), lr=0.0001)\n",
    "optimizer_decoder = optim.Adam(decoder.parameters(), lr=0.0001)\n",
    "optimizerD = optim.Adam(discriminator.parameters(), lr=0.0001)\n",
    "# 初始化损失函数\n",
    "criterion_BCE = nn.BCEWithLogitsLoss().to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/20][0/200] Loss_D: 6.4282 Loss_VAE: 2.8133\n",
      "[0/20][100/200] Loss_D: 0.0039 Loss_VAE: 3590898176.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Project\\ZLTProgram\\TrainCVAE_GAN_Cifar10.ipynb Cell 2\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Project/ZLTProgram/TrainCVAE_GAN_Cifar10.ipynb#W1sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m[\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m][\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m] Loss_D: \u001b[39m\u001b[39m%.4f\u001b[39;00m\u001b[39m Loss_VAE: \u001b[39m\u001b[39m%.4f\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Project/ZLTProgram/TrainCVAE_GAN_Cifar10.ipynb#W1sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m           \u001b[39m%\u001b[39m (epoch, num_epoch, i, \u001b[39mlen\u001b[39m(dataloader),\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Project/ZLTProgram/TrainCVAE_GAN_Cifar10.ipynb#W1sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m              d_loss\u001b[39m.\u001b[39mitem(),vae_loss\u001b[39m.\u001b[39mitem()))\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Project/ZLTProgram/TrainCVAE_GAN_Cifar10.ipynb#W1sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mif\u001b[39;00m epoch\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Project/ZLTProgram/TrainCVAE_GAN_Cifar10.ipynb#W1sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     real_images \u001b[39m=\u001b[39m make_grid(data\u001b[39m.\u001b[39;49mcpu(), nrow\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, normalize\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mdetach()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Project/ZLTProgram/TrainCVAE_GAN_Cifar10.ipynb#W1sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     save_image(real_images, \u001b[39m'\u001b[39m\u001b[39m./img_CVAE-GAN_Cifar10/real_images.png\u001b[39m\u001b[39m'\u001b[39m) \n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Project/ZLTProgram/TrainCVAE_GAN_Cifar10.ipynb#W1sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(dataloader)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练cVAE-GAN\n",
    "for epoch in range(num_epoch):\n",
    "      for i,(data,label) in enumerate(dataloader,0):\n",
    "            data=data.to(device)\n",
    "            label=label.to(device)\n",
    "            batch_size=data.shape[0]\n",
    "            # 训练判别器\n",
    "            real_output=discriminator(data,label)\n",
    "            real_output=real_output.squeeze()\n",
    "            #print(real_output.shape)\n",
    "            real_label=torch.ones(batch_size).to(device)\n",
    "           # print(real_label.shape)\n",
    "            fake_label=torch.zeros(batch_size).to(device)\n",
    "            d_loss_real=criterion_BCE(real_output,real_label)\n",
    "            # VAE重构图片\n",
    "            # z,mean,logstd = encoder(data)\n",
    "            z=torch.randn(batch_size,80).to(device)\n",
    "            fake_data=decoder(z,label)\n",
    "            fake_output=discriminator(fake_data,label)\n",
    "            fake_output=fake_output.squeeze()\n",
    "            d_loss_fake=criterion_BCE(fake_output,fake_label)\n",
    "            d_loss=d_loss_real+d_loss_fake\n",
    "            optimizerD.zero_grad()\n",
    "            d_loss.backward()\n",
    "            optimizerD.step()\n",
    "            #print(\"Discriminator_Loss\",d_loss)\n",
    "            \n",
    "            #训练VAE\n",
    "            z2,mean,logstd = encoder(data)\n",
    "            recon_data =decoder(z2,label)\n",
    "            # 计算重构图片与潜在向量之间的损失 \n",
    "            vae_loss_recon=loss_function(recon_x=recon_data,\n",
    "                                         x=data,\n",
    "                                         mean=mean,\n",
    "                                         logstd=logstd,\n",
    "                                         device=device\n",
    "                                         )\n",
    "            # 计算判别器损失\n",
    "            output=discriminator(recon_data,label)\n",
    "            output=output.squeeze()\n",
    "            real_label = torch.ones(batch_size).to(device)\n",
    "            vae_loss_d = criterion_BCE(output,real_label)\n",
    "            vae_loss=(vae_loss_recon+vae_loss_d)*0.01\n",
    "            #print(\"VAE_Loss:\",vae_loss)\n",
    "            optimizer_decoder.zero_grad()\n",
    "            optimizer_encoder.zero_grad()\n",
    "            # 反向传播更新VAE参数\n",
    "            vae_loss.backward()\n",
    "            optimizer_decoder.step()\n",
    "            optimizer_encoder.step()\n",
    "            \n",
    "            \n",
    "           \n",
    "            #训练分类器\n",
    "            if i%100==0:\n",
    "                print('[%d/%d][%d/%d] Loss_D: %.4f Loss_VAE: %.4f'\n",
    "                      % (epoch, num_epoch, i, len(dataloader),\n",
    "                         d_loss.item(),vae_loss.item()))\n",
    "               \n",
    "            if epoch==0:\n",
    "                real_images = make_grid(data.cpu(), nrow=8, normalize=True).detach()\n",
    "                save_image(real_images, './img_CVAE-GAN_Cifar10/real_images.png') \n",
    "            if i == len(dataloader)-1:\n",
    "                sample = torch.randn(data.shape[0],z_dimension).to(device)\n",
    "                output = decoder(sample,label)\n",
    "                fake_images = make_grid(output.cpu(), nrow=8, normalize=True).detach()\n",
    "                save_image(fake_images, './img_CVAE-GAN_Cifar10/fake_images-{}.png'.format(epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), 'E:/Project/ModelAndDataset/model/CVAE-GAN-Cifar10-Encoder.pth')\n",
    "torch.save(decoder.state_dict(),'E:/Project/ModelAndDataset/model/CVAE-GAN-Cifar10-Decoder.pth')\n",
    "torch.save(discriminator.state_dict(),'E:/Project/ModelAndDataset/model/CVAE-GAN-Cifar10-Discriminator.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AdversarialSampleDetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
