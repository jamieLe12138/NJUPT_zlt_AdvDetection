{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CVAE_BigGAN import Generator_cifar10,Discriminator_cifar10\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "G=Generator(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (linear0): Linear(in_features=20, out_features=6144, bias=True)\n",
       "  (shared): Embedding(10, 128)\n",
       "  (blocks): ModuleList(\n",
       "    (0-1): 2 x GenBlock(\n",
       "      (bn1): ConditionalBatchNorm2d_for_skip_and_shared(\n",
       "        (bn): BatchNorm2d(384, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
       "        (gain): Linear(in_features=148, out_features=384, bias=False)\n",
       "        (bias): Linear(in_features=148, out_features=384, bias=False)\n",
       "      )\n",
       "      (bn2): ConditionalBatchNorm2d_for_skip_and_shared(\n",
       "        (bn): BatchNorm2d(384, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
       "        (gain): Linear(in_features=148, out_features=384, bias=False)\n",
       "        (bias): Linear(in_features=148, out_features=384, bias=False)\n",
       "      )\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (conv2d0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2d1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2d2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (2): Self_Attn(\n",
       "      (conv1x1_theta): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv1x1_phi): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv1x1_g): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv1x1_attn): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (3): GenBlock(\n",
       "      (bn1): ConditionalBatchNorm2d_for_skip_and_shared(\n",
       "        (bn): BatchNorm2d(384, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
       "        (gain): Linear(in_features=148, out_features=384, bias=False)\n",
       "        (bias): Linear(in_features=148, out_features=384, bias=False)\n",
       "      )\n",
       "      (bn2): ConditionalBatchNorm2d_for_skip_and_shared(\n",
       "        (bn): BatchNorm2d(384, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
       "        (gain): Linear(in_features=148, out_features=384, bias=False)\n",
       "        (bias): Linear(in_features=148, out_features=384, bias=False)\n",
       "      )\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (conv2d0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2d1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2d2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (bn4): BatchNorm2d(384, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (activation): ReLU(inplace=True)\n",
       "  (conv2d5): Conv2d(384, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (blocks): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): DiscOptBlock(\n",
       "        (conv2d0): Conv2d(3, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv2d1): Conv2d(3, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2d2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU(inplace=True)\n",
       "        (average_pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): Self_Attn(\n",
       "        (conv1x1_theta): Conv2d(192, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1x1_phi): Conv2d(192, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1x1_g): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1x1_attn): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): DiscBlock(\n",
       "        (activation): ReLU(inplace=True)\n",
       "        (conv2d0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv2d1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2d2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (average_pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "    )\n",
       "    (3-4): 2 x ModuleList(\n",
       "      (0): DiscBlock(\n",
       "        (activation): ReLU(inplace=True)\n",
       "        (conv2d1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2d2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (average_pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (activation): ReLU(inplace=True)\n",
       "  (linear1): Linear(in_features=192, out_features=1, bias=True)\n",
       "  (embedding): Embedding(10, 192)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D=Discriminator()\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "import torch\n",
    "\n",
    "z=torch.randn(64,80)\n",
    "label=y = torch.randint(low=0, high=9, size=(64,))\n",
    "out=G(z,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=D(out,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1756,  0.0343,  0.3997,  ...,  0.1668,  0.2619, -0.0214],\n",
       "          [-0.0755, -0.0737, -0.0554,  ..., -0.3389,  0.2583, -0.3795],\n",
       "          [-0.3930, -0.0505,  0.2431,  ...,  0.2447,  0.4221, -0.1420],\n",
       "          ...,\n",
       "          [ 0.6308,  0.5408,  0.7691,  ...,  0.2204,  0.3232, -0.5180],\n",
       "          [ 0.4189,  0.5025,  0.5029,  ...,  0.1130,  0.3512, -0.5140],\n",
       "          [ 0.3149,  0.7390,  0.5831,  ..., -0.0738,  0.1837, -0.4683]],\n",
       "\n",
       "         [[-0.1919,  0.0681,  0.1813,  ..., -0.2919, -0.1873, -0.1361],\n",
       "          [-0.1716, -0.0993,  0.0462,  ..., -0.2489, -0.2454,  0.1018],\n",
       "          [-0.1440, -0.1801, -0.1149,  ..., -0.2092, -0.3241,  0.2470],\n",
       "          ...,\n",
       "          [ 0.3967,  0.3081, -0.1689,  ..., -0.0863,  0.3283,  0.4973],\n",
       "          [ 0.3510,  0.0383, -0.0526,  ...,  0.2282, -0.1096,  0.3554],\n",
       "          [-0.0174, -0.3714, -0.4405,  ..., -0.2498, -0.2880, -0.0797]],\n",
       "\n",
       "         [[ 0.2941,  0.5242,  0.2645,  ...,  0.0568,  0.4581,  0.0308],\n",
       "          [ 0.5543,  0.7669,  0.7765,  ...,  0.2063,  0.4722,  0.2863],\n",
       "          [ 0.6889,  0.9075,  0.8135,  ...,  0.5437,  0.6838,  0.3559],\n",
       "          ...,\n",
       "          [ 0.4855,  0.6145,  0.6440,  ...,  0.3038,  0.5159,  0.5964],\n",
       "          [ 0.5544,  0.6750,  0.7089,  ...,  0.2529,  0.4859,  0.6430],\n",
       "          [ 0.4203,  0.6904,  0.6105,  ...,  0.5690,  0.5909,  0.3844]]],\n",
       "\n",
       "\n",
       "        [[[-0.3600, -0.1880,  0.0828,  ..., -0.3854, -0.2161,  0.0831],\n",
       "          [-0.3626, -0.5879, -0.5041,  ..., -0.1130,  0.0499, -0.2717],\n",
       "          [-0.5259, -0.4212, -0.4460,  ..., -0.0465, -0.1452, -0.4414],\n",
       "          ...,\n",
       "          [ 0.3548,  0.6203,  0.7228,  ...,  0.0901,  0.1760, -0.0470],\n",
       "          [ 0.3519,  0.6673,  0.8873,  ...,  0.6006,  0.6167,  0.1646],\n",
       "          [ 0.1171,  0.4230,  0.6023,  ...,  0.0073,  0.1996,  0.1260]],\n",
       "\n",
       "         [[-0.0518,  0.0172,  0.0075,  ..., -0.1951, -0.2748, -0.4123],\n",
       "          [ 0.0641, -0.3102,  0.0522,  ..., -0.3232, -0.1702, -0.3769],\n",
       "          [-0.0063, -0.1112, -0.2293,  ..., -0.3318, -0.0443, -0.4815],\n",
       "          ...,\n",
       "          [ 0.2694,  0.3754, -0.3422,  ...,  0.1107,  0.0626, -0.0744],\n",
       "          [-0.0687,  0.1194, -0.2956,  ...,  0.2055,  0.1494,  0.1466],\n",
       "          [-0.3068, -0.2360, -0.5427,  ..., -0.2895, -0.0780, -0.0640]],\n",
       "\n",
       "         [[ 0.4863,  0.6193,  0.7558,  ...,  0.2775,  0.2992,  0.2143],\n",
       "          [ 0.7939,  0.9169,  0.9159,  ...,  0.2733,  0.4879,  0.3585],\n",
       "          [ 0.8279,  0.9580,  0.8944,  ...,  0.1894,  0.4062,  0.1022],\n",
       "          ...,\n",
       "          [ 0.6797,  0.6825,  0.5155,  ...,  0.0269,  0.2381,  0.2440],\n",
       "          [ 0.5503,  0.6416,  0.4995,  ...,  0.3444,  0.3636,  0.4384],\n",
       "          [ 0.6656,  0.7605,  0.8392,  ...,  0.5970,  0.3955,  0.0344]]],\n",
       "\n",
       "\n",
       "        [[[-0.2666, -0.5359, -0.5289,  ..., -0.2128,  0.1393,  0.2207],\n",
       "          [-0.2835, -0.6382, -0.5090,  ..., -0.3006,  0.3524,  0.2085],\n",
       "          [ 0.0212, -0.1596, -0.3660,  ...,  0.0437,  0.6782,  0.4600],\n",
       "          ...,\n",
       "          [-0.0509, -0.5393,  0.0707,  ...,  0.3558,  0.0878,  0.0394],\n",
       "          [ 0.1127, -0.3804,  0.0701,  ..., -0.0940, -0.0350, -0.0298],\n",
       "          [ 0.2445, -0.1104,  0.0984,  ...,  0.1828,  0.2209,  0.0956]],\n",
       "\n",
       "         [[-0.0301, -0.1653, -0.3454,  ..., -0.4846, -0.1597, -0.2091],\n",
       "          [-0.3079, -0.3988, -0.1404,  ..., -0.5421, -0.3188, -0.3594],\n",
       "          [-0.2084, -0.2132,  0.0491,  ..., -0.7294, -0.7828, -0.3493],\n",
       "          ...,\n",
       "          [ 0.0870,  0.3418,  0.3264,  ..., -0.6152, -0.7468, -0.1969],\n",
       "          [-0.1601, -0.2947, -0.0859,  ..., -0.6040, -0.4681, -0.1618],\n",
       "          [-0.0534, -0.3762, -0.2423,  ..., -0.5819, -0.3082, -0.2558]],\n",
       "\n",
       "         [[ 0.5169,  0.6430,  0.5612,  ..., -0.0282,  0.2813,  0.5109],\n",
       "          [ 0.7564,  0.5285,  0.6932,  ..., -0.4462, -0.2374,  0.4186],\n",
       "          [ 0.7256,  0.5880,  0.8010,  ..., -0.2392, -0.0810,  0.3075],\n",
       "          ...,\n",
       "          [ 0.6324,  0.8473,  0.7329,  ...,  0.7679,  0.6078,  0.4583],\n",
       "          [ 0.4730,  0.7560,  0.7710,  ...,  0.9104,  0.8093,  0.7001],\n",
       "          [ 0.5363,  0.6611,  0.5960,  ...,  0.8703,  0.8245,  0.3773]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.0429, -0.1431,  0.1360,  ...,  0.1559,  0.3052, -0.0052],\n",
       "          [-0.0796,  0.1249, -0.0587,  ...,  0.0027,  0.2796,  0.0458],\n",
       "          [ 0.0176,  0.2614, -0.3300,  ..., -0.3811,  0.4866,  0.0789],\n",
       "          ...,\n",
       "          [ 0.3302,  0.4863,  0.3935,  ...,  0.2341,  0.6743,  0.4843],\n",
       "          [ 0.1162,  0.4581,  0.5153,  ..., -0.0508,  0.2881,  0.2024],\n",
       "          [ 0.1560,  0.2645,  0.2142,  ...,  0.2887,  0.3418,  0.1111]],\n",
       "\n",
       "         [[ 0.2112,  0.0387, -0.0610,  ..., -0.4296, -0.2813, -0.1506],\n",
       "          [-0.0411, -0.4421, -0.1845,  ..., -0.6799, -0.5407, -0.4434],\n",
       "          [-0.3178, -0.6541, -0.5391,  ..., -0.8595, -0.7318, -0.4872],\n",
       "          ...,\n",
       "          [-0.3864, -0.3315, -0.6952,  ..., -0.2857, -0.1672, -0.2950],\n",
       "          [-0.4054, -0.4326, -0.5745,  ..., -0.3475, -0.4418, -0.1138],\n",
       "          [-0.5680, -0.6991, -0.7290,  ..., -0.6937, -0.6851, -0.3550]],\n",
       "\n",
       "         [[ 0.2412,  0.3549,  0.4470,  ...,  0.5802,  0.5573,  0.5368],\n",
       "          [ 0.4517,  0.3707,  0.3440,  ...,  0.5675,  0.4840,  0.4868],\n",
       "          [ 0.5307,  0.4578,  0.2472,  ...,  0.4906,  0.0676,  0.2979],\n",
       "          ...,\n",
       "          [ 0.5183,  0.8165,  0.8263,  ...,  0.8435,  0.7493,  0.6136],\n",
       "          [ 0.3585,  0.4552,  0.1539,  ...,  0.7498,  0.4965,  0.5418],\n",
       "          [ 0.2983,  0.3539,  0.3552,  ...,  0.7554,  0.6727,  0.3941]]],\n",
       "\n",
       "\n",
       "        [[[-0.0348,  0.1699, -0.0812,  ...,  0.3423,  0.1349,  0.3589],\n",
       "          [ 0.2825,  0.2070,  0.0218,  ...,  0.5326,  0.2427,  0.0143],\n",
       "          [ 0.1879,  0.4870, -0.1171,  ...,  0.7764,  0.5757,  0.2152],\n",
       "          ...,\n",
       "          [-0.3692,  0.0410, -0.0491,  ...,  0.0641,  0.0294, -0.0141],\n",
       "          [-0.1071,  0.1315,  0.1762,  ...,  0.6952,  0.3966,  0.2980],\n",
       "          [ 0.3074,  0.2896,  0.3123,  ...,  0.3698,  0.2596,  0.0309]],\n",
       "\n",
       "         [[ 0.5164,  0.5861,  0.3967,  ...,  0.1339,  0.3801,  0.2505],\n",
       "          [ 0.1140, -0.0350, -0.2193,  ...,  0.5179,  0.4169,  0.4867],\n",
       "          [ 0.5499,  0.1427,  0.1387,  ...,  0.3604,  0.4767,  0.5885],\n",
       "          ...,\n",
       "          [ 0.0521,  0.2529,  0.0448,  ..., -0.3512, -0.1671,  0.0196],\n",
       "          [-0.0188, -0.1884, -0.3130,  ..., -0.5724, -0.5646, -0.2986],\n",
       "          [-0.1378, -0.4990, -0.4592,  ..., -0.5845, -0.7105, -0.4168]],\n",
       "\n",
       "         [[ 0.0580,  0.4758,  0.2999,  ...,  0.5139,  0.3758,  0.4049],\n",
       "          [ 0.5026,  0.6791,  0.8794,  ...,  0.4449,  0.4876,  0.6301],\n",
       "          [ 0.4378,  0.7783,  0.8794,  ...,  0.6898,  0.6320,  0.7353],\n",
       "          ...,\n",
       "          [ 0.0589,  0.0799,  0.2993,  ...,  0.4291,  0.4329,  0.4785],\n",
       "          [ 0.1537,  0.0614,  0.1630,  ...,  0.7905,  0.6118,  0.7070],\n",
       "          [ 0.4180,  0.4265,  0.2057,  ...,  0.8167,  0.7422,  0.5246]]],\n",
       "\n",
       "\n",
       "        [[[-0.6157, -0.7642, -0.5098,  ..., -0.2831, -0.2814, -0.1298],\n",
       "          [ 0.0561, -0.3349, -0.1869,  ..., -0.4267, -0.4040, -0.4083],\n",
       "          [-0.1171, -0.3826, -0.1356,  ..., -0.4275, -0.2052, -0.0629],\n",
       "          ...,\n",
       "          [-0.2539, -0.2990, -0.1027,  ..., -0.2113,  0.1046, -0.0051],\n",
       "          [-0.0733, -0.0581,  0.0264,  ..., -0.4232,  0.0888, -0.2369],\n",
       "          [-0.0263, -0.3432, -0.1509,  ..., -0.1313, -0.1121, -0.0598]],\n",
       "\n",
       "         [[ 0.2795, -0.0516, -0.1183,  ..., -0.3146, -0.3515, -0.4153],\n",
       "          [-0.0150, -0.6703, -0.6766,  ..., -0.1576, -0.1983, -0.4174],\n",
       "          [ 0.1021, -0.6790, -0.7230,  ..., -0.5820, -0.3151, -0.3382],\n",
       "          ...,\n",
       "          [ 0.2450, -0.4395, -0.5736,  ..., -0.4505, -0.3104,  0.1204],\n",
       "          [ 0.3221, -0.3858, -0.3768,  ...,  0.0465,  0.0615,  0.2552],\n",
       "          [ 0.0727, -0.2730, -0.4173,  ..., -0.3740, -0.1976,  0.0793]],\n",
       "\n",
       "         [[ 0.3515,  0.3334,  0.4161,  ...,  0.4680,  0.5632,  0.3405],\n",
       "          [ 0.3566,  0.3884,  0.1908,  ...,  0.4899,  0.6879,  0.6527],\n",
       "          [ 0.2040,  0.6505,  0.4015,  ...,  0.4479,  0.6533,  0.6270],\n",
       "          ...,\n",
       "          [ 0.8646,  0.8460,  0.8303,  ...,  0.9267,  0.7927,  0.7505],\n",
       "          [ 0.8807,  0.8808,  0.8940,  ...,  0.8198,  0.7552,  0.7618],\n",
       "          [ 0.5941,  0.6197,  0.6293,  ...,  0.6715,  0.5897,  0.4188]]]],\n",
       "       device='cuda:0', grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-11.7743,   4.4911,   6.5920, -12.2682,   7.3174,   2.5422, -13.2805,\n",
       "          7.6894,  -4.7463,   7.0470,  -4.3963, -11.4718,  -0.6182,   1.0888,\n",
       "          7.4481,   6.5866,   6.0252,   6.5031,   1.4942,  -5.4911,  -3.8328,\n",
       "         -5.2339,   0.7144,  -0.2123,   5.7546,   4.6355,   1.0531,   3.2156,\n",
       "          5.6884,   2.6379,   6.9407,   5.2106,   5.8678,  -3.4835,   0.6650,\n",
       "         -2.1497,  -5.5858, -11.0148,  -0.8630, -11.0143,   5.6230,   3.3726,\n",
       "          4.7930,   2.1789,   6.9325,   3.2679,  -3.0042,   1.2379,  -0.2793,\n",
       "          6.3868,   6.0173,  -4.2547, -12.1090,   1.8659, -11.9679,  -5.1796,\n",
       "         -5.7552,   1.6038,   0.4649,   1.2955,   5.4431,   4.6915,   1.8435,\n",
       "          0.8749], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"architecture\": \"big_resnet\",\n",
    "#         \"conditional_strategy\": \"ProjGAN\",\n",
    "#         \"pos_collected_numerator\": false,\n",
    "#         \"hypersphere_dim\": \"N/A\",\n",
    "#         \"nonlinear_embed\": false,\n",
    "#         \"normalize_embed\": false,\n",
    "#         \"g_spectral_norm\": true,\n",
    "#         \"d_spectral_norm\": true,\n",
    "#         \"activation_fn\": \"ReLU\",\n",
    "#         \"attention\": true,\n",
    "#         \"attention_after_nth_gen_block\": 2,\n",
    "#         \"attention_after_nth_dis_block\": 1,\n",
    "#         \"z_dim\": 80,\n",
    "#         \"shared_dim\": 128,\n",
    "#         \"g_conv_dim\": 96,\n",
    "#         \"d_conv_dim\": 96,\n",
    "#         \"G_depth\":\"N/A\",\n",
    "#         \"D_depth\":\"N/A\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AdversarialSampleDetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
