{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from studioGAN.CVAE_BigGAN import Generator_cifar10,Discriminator_cifar10\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "G=Generator_cifar10(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator_cifar10(\n",
       "  (linear0): Linear(in_features=20, out_features=6144, bias=True)\n",
       "  (shared): Embedding(10, 128)\n",
       "  (blocks): ModuleList(\n",
       "    (0-1): 2 x GenBlock(\n",
       "      (bn1): ConditionalBatchNorm2d_for_skip_and_shared(\n",
       "        (bn): BatchNorm2d(384, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
       "        (gain): Linear(in_features=148, out_features=384, bias=False)\n",
       "        (bias): Linear(in_features=148, out_features=384, bias=False)\n",
       "      )\n",
       "      (bn2): ConditionalBatchNorm2d_for_skip_and_shared(\n",
       "        (bn): BatchNorm2d(384, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
       "        (gain): Linear(in_features=148, out_features=384, bias=False)\n",
       "        (bias): Linear(in_features=148, out_features=384, bias=False)\n",
       "      )\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (conv2d0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2d1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2d2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (2): Self_Attn(\n",
       "      (conv1x1_theta): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv1x1_phi): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv1x1_g): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (conv1x1_attn): Conv2d(192, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (softmax): Softmax(dim=-1)\n",
       "    )\n",
       "    (3): GenBlock(\n",
       "      (bn1): ConditionalBatchNorm2d_for_skip_and_shared(\n",
       "        (bn): BatchNorm2d(384, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
       "        (gain): Linear(in_features=148, out_features=384, bias=False)\n",
       "        (bias): Linear(in_features=148, out_features=384, bias=False)\n",
       "      )\n",
       "      (bn2): ConditionalBatchNorm2d_for_skip_and_shared(\n",
       "        (bn): BatchNorm2d(384, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
       "        (gain): Linear(in_features=148, out_features=384, bias=False)\n",
       "        (bias): Linear(in_features=148, out_features=384, bias=False)\n",
       "      )\n",
       "      (activation): ReLU(inplace=True)\n",
       "      (conv2d0): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2d1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2d2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (bn4): BatchNorm2d(384, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (activation): ReLU(inplace=True)\n",
       "  (conv2d5): Conv2d(384, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator_cifar10(\n",
       "  (blocks): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): DiscOptBlock(\n",
       "        (conv2d0): Conv2d(3, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv2d1): Conv2d(3, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2d2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU(inplace=True)\n",
       "        (average_pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): Self_Attn(\n",
       "        (conv1x1_theta): Conv2d(192, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1x1_phi): Conv2d(192, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1x1_g): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1x1_attn): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): DiscBlock(\n",
       "        (activation): ReLU(inplace=True)\n",
       "        (conv2d0): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv2d1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2d2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (average_pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "    )\n",
       "    (3-4): 2 x ModuleList(\n",
       "      (0): DiscBlock(\n",
       "        (activation): ReLU(inplace=True)\n",
       "        (conv2d1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2d2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (average_pooling): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (activation): ReLU(inplace=True)\n",
       "  (linear1): Linear(in_features=192, out_features=1, bias=True)\n",
       "  (embedding): Embedding(10, 192)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D=Discriminator_cifar10()\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn\n",
    "import torch\n",
    "\n",
    "z=torch.randn(64,80)\n",
    "label=y = torch.randint(low=0, high=9, size=(64,))\n",
    "out=G(z,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=D(out,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.3795, -0.4082, -0.3602,  ..., -0.0492,  0.0848,  0.0802],\n",
       "          [-0.2828, -0.6664, -0.6057,  ..., -0.1851, -0.0192, -0.1854],\n",
       "          [ 0.0493, -0.5167, -0.5704,  ..., -0.3772, -0.0824, -0.0789],\n",
       "          ...,\n",
       "          [-0.2434, -0.3691, -0.0229,  ..., -0.0507,  0.1178,  0.0061],\n",
       "          [-0.0548,  0.0252, -0.2440,  ..., -0.5183, -0.3933, -0.4411],\n",
       "          [-0.1858, -0.0552, -0.0506,  ...,  0.1565,  0.0322,  0.0681]],\n",
       "\n",
       "         [[ 0.6611,  0.7204,  0.7598,  ..., -0.0343,  0.3639, -0.0075],\n",
       "          [ 0.3605,  0.3025, -0.0256,  ...,  0.1407,  0.2565, -0.2602],\n",
       "          [ 0.5170,  0.2150, -0.2568,  ...,  0.1079,  0.1375, -0.1268],\n",
       "          ...,\n",
       "          [-0.1213,  0.2581, -0.4669,  ...,  0.3994,  0.3711, -0.2738],\n",
       "          [-0.0608,  0.0376, -0.3149,  ...,  0.3344,  0.2319, -0.0899],\n",
       "          [-0.2497,  0.0048, -0.2857,  ..., -0.2951,  0.0612,  0.1303]],\n",
       "\n",
       "         [[ 0.3329, -0.2621,  0.1052,  ...,  0.3571,  0.4494, -0.0835],\n",
       "          [ 0.0896, -0.4941, -0.0481,  ...,  0.4170,  0.2093, -0.0840],\n",
       "          [-0.0538, -0.2430,  0.0038,  ...,  0.0211, -0.4430, -0.3991],\n",
       "          ...,\n",
       "          [ 0.1576,  0.0454,  0.3989,  ...,  0.5176, -0.0496,  0.1967],\n",
       "          [-0.2373, -0.0030,  0.0863,  ...,  0.3586, -0.1269,  0.0259],\n",
       "          [-0.3386,  0.1595,  0.0700,  ...,  0.2113, -0.1989,  0.0091]]],\n",
       "\n",
       "\n",
       "        [[[-0.4823,  0.0254,  0.2154,  ..., -0.1148,  0.0493,  0.1724],\n",
       "          [-0.0316,  0.1132,  0.1933,  ..., -0.1465,  0.3366, -0.1392],\n",
       "          [-0.0578,  0.0982,  0.1554,  ..., -0.0443,  0.1112, -0.2572],\n",
       "          ...,\n",
       "          [-0.0735,  0.0674, -0.3540,  ..., -0.0826, -0.4723,  0.0446],\n",
       "          [ 0.1741,  0.0376, -0.3453,  ...,  0.2340, -0.2570, -0.2264],\n",
       "          [ 0.4593,  0.1399, -0.4004,  ..., -0.1084, -0.3949, -0.3470]],\n",
       "\n",
       "         [[ 0.3195, -0.1577, -0.0025,  ..., -0.0943,  0.1367,  0.0682],\n",
       "          [-0.1565, -0.4008, -0.4831,  ..., -0.6882, -0.5124, -0.5031],\n",
       "          [-0.0284, -0.3503, -0.3720,  ..., -0.6334, -0.2077, -0.2870],\n",
       "          ...,\n",
       "          [ 0.1541,  0.3084,  0.5008,  ..., -0.3211,  0.2966, -0.3842],\n",
       "          [ 0.0709,  0.3528,  0.4397,  ...,  0.2375,  0.3071, -0.4272],\n",
       "          [-0.4575,  0.1266,  0.0838,  ..., -0.2316, -0.2852, -0.5708]],\n",
       "\n",
       "         [[ 0.4290,  0.2592,  0.3903,  ..., -0.0103, -0.0453,  0.3330],\n",
       "          [ 0.1484,  0.2596,  0.0521,  ...,  0.1642,  0.2196,  0.5223],\n",
       "          [-0.0820,  0.2443,  0.0553,  ..., -0.0585, -0.0428,  0.3820],\n",
       "          ...,\n",
       "          [-0.2429, -0.2699, -0.4960,  ...,  0.3790,  0.2670,  0.2615],\n",
       "          [-0.1086, -0.3543, -0.5000,  ..., -0.0859,  0.0911,  0.0852],\n",
       "          [-0.1197, -0.3515, -0.5874,  ..., -0.5801, -0.3583, -0.3231]]],\n",
       "\n",
       "\n",
       "        [[[-0.4062, -0.3963, -0.3422,  ..., -0.1604, -0.2798, -0.1546],\n",
       "          [-0.3964, -0.2179, -0.3820,  ..., -0.2539, -0.2873, -0.1092],\n",
       "          [-0.2956, -0.3636, -0.2522,  ...,  0.0327, -0.5484, -0.0905],\n",
       "          ...,\n",
       "          [-0.4418, -0.9184, -0.7975,  ...,  0.0376, -0.2661,  0.0259],\n",
       "          [-0.3263, -0.8219, -0.6106,  ...,  0.4678, -0.2278, -0.2943],\n",
       "          [-0.3545, -0.4474, -0.3664,  ...,  0.1527, -0.3810, -0.3956]],\n",
       "\n",
       "         [[ 0.5969,  0.3434,  0.2412,  ..., -0.2928, -0.0536, -0.1931],\n",
       "          [ 0.1984,  0.3038, -0.0634,  ..., -0.6168, -0.4698, -0.5081],\n",
       "          [ 0.5499, -0.0301, -0.1202,  ..., -0.7808, -0.4031, -0.5352],\n",
       "          ...,\n",
       "          [ 0.3283,  0.2336, -0.3877,  ..., -0.3736, -0.1871, -0.2112],\n",
       "          [ 0.3924,  0.2828, -0.0311,  ...,  0.0054, -0.2261, -0.4550],\n",
       "          [ 0.1517,  0.2561, -0.0840,  ..., -0.1622, -0.1731, -0.1827]],\n",
       "\n",
       "         [[-0.0278,  0.1023, -0.2083,  ...,  0.0215,  0.3177,  0.4097],\n",
       "          [-0.0073, -0.0374, -0.3918,  ...,  0.1492,  0.4253,  0.5415],\n",
       "          [-0.1769,  0.0880, -0.2437,  ...,  0.1369,  0.5544,  0.7063],\n",
       "          ...,\n",
       "          [-0.4587, -0.0661, -0.1312,  ...,  0.2598,  0.2535,  0.4357],\n",
       "          [-0.4358, -0.2712, -0.2890,  ...,  0.0872,  0.1539,  0.5291],\n",
       "          [-0.6578, -0.4295, -0.5007,  ..., -0.2101, -0.2786, -0.1533]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.2719, -0.3512, -0.1772,  ...,  0.3099,  0.1497,  0.1161],\n",
       "          [-0.3610, -0.5778, -0.2714,  ...,  0.4208,  0.0413,  0.1231],\n",
       "          [-0.0876, -0.2626, -0.1024,  ...,  0.1874, -0.2103, -0.0761],\n",
       "          ...,\n",
       "          [-0.3412, -0.1181,  0.0187,  ...,  0.2727, -0.0319,  0.3312],\n",
       "          [-0.2788,  0.2072,  0.1542,  ..., -0.1250, -0.3357, -0.3346],\n",
       "          [-0.0638,  0.0345, -0.0987,  ..., -0.3233, -0.3720, -0.2273]],\n",
       "\n",
       "         [[ 0.3895,  0.2638,  0.1334,  ..., -0.0918,  0.3477,  0.0700],\n",
       "          [-0.0369,  0.2448, -0.1038,  ..., -0.2490,  0.4088, -0.2442],\n",
       "          [-0.0273,  0.2394, -0.3381,  ..., -0.4078,  0.2744, -0.1866],\n",
       "          ...,\n",
       "          [-0.1702, -0.2709, -0.5943,  ..., -0.7328, -0.3249, -0.5758],\n",
       "          [-0.0485, -0.2268, -0.4875,  ..., -0.2772,  0.1554, -0.2844],\n",
       "          [-0.3342, -0.0309, -0.2805,  ..., -0.1814, -0.0350, -0.0446]],\n",
       "\n",
       "         [[ 0.4056, -0.0796,  0.0930,  ...,  0.0178,  0.0231,  0.3153],\n",
       "          [ 0.0048,  0.0885,  0.3045,  ..., -0.0291,  0.0486,  0.1545],\n",
       "          [-0.3315,  0.2462,  0.3149,  ...,  0.3411,  0.1970,  0.2051],\n",
       "          ...,\n",
       "          [-0.1626,  0.1763,  0.3219,  ...,  0.1563, -0.1462,  0.4996],\n",
       "          [-0.0903, -0.1506,  0.0912,  ..., -0.2376, -0.0035,  0.4262],\n",
       "          [-0.3693, -0.2124, -0.4303,  ..., -0.1331, -0.0323,  0.1523]]],\n",
       "\n",
       "\n",
       "        [[[-0.2508, -0.3157, -0.4290,  ...,  0.5018,  0.4505,  0.2296],\n",
       "          [-0.2194, -0.4705, -0.3333,  ...,  0.5556,  0.3745,  0.0399],\n",
       "          [-0.1025, -0.1619,  0.0582,  ...,  0.4914,  0.3580, -0.1842],\n",
       "          ...,\n",
       "          [-0.4497, -0.5573, -0.2435,  ...,  0.7636,  0.3368,  0.1727],\n",
       "          [-0.3644, -0.6234, -0.4112,  ...,  0.5041,  0.1377, -0.1843],\n",
       "          [-0.0381, -0.3424, -0.2405,  ...,  0.2705, -0.0789, -0.3467]],\n",
       "\n",
       "         [[ 0.4499,  0.3223,  0.4074,  ..., -0.0351,  0.0237, -0.1179],\n",
       "          [ 0.2696,  0.0422,  0.1749,  ..., -0.4874, -0.2440, -0.3538],\n",
       "          [ 0.1084, -0.1715, -0.1833,  ..., -0.7004, -0.4195, -0.2194],\n",
       "          ...,\n",
       "          [ 0.2016,  0.2624,  0.2129,  ..., -0.2011, -0.1748, -0.4828],\n",
       "          [ 0.2115,  0.3307,  0.0784,  ...,  0.1616, -0.0019, -0.1105],\n",
       "          [-0.3181,  0.1920, -0.3971,  ...,  0.0115,  0.1676,  0.0827]],\n",
       "\n",
       "         [[-0.2187, -0.5280, -0.1422,  ..., -0.0271, -0.0276,  0.2117],\n",
       "          [ 0.2611,  0.1218,  0.5143,  ..., -0.1349, -0.1044,  0.1662],\n",
       "          [ 0.1012,  0.3080,  0.6919,  ...,  0.0708, -0.0567,  0.3317],\n",
       "          ...,\n",
       "          [-0.4903, -0.6606, -0.6427,  ...,  0.3119,  0.2374,  0.4987],\n",
       "          [-0.0680, -0.5618, -0.6291,  ...,  0.1762,  0.0968,  0.6163],\n",
       "          [-0.2168, -0.2019, -0.3570,  ...,  0.1326, -0.0703,  0.2639]]],\n",
       "\n",
       "\n",
       "        [[[-0.3839, -0.0541, -0.0784,  ...,  0.4485,  0.4160,  0.1013],\n",
       "          [-0.3555, -0.5519, -0.3636,  ...,  0.0746,  0.3305, -0.0757],\n",
       "          [-0.0011, -0.2204,  0.3136,  ...,  0.4210,  0.3391, -0.1979],\n",
       "          ...,\n",
       "          [-0.4518, -0.3590, -0.1265,  ...,  0.5263,  0.3063, -0.0675],\n",
       "          [-0.5779, -0.5641, -0.3711,  ...,  0.1257,  0.0969, -0.2129],\n",
       "          [-0.2544, -0.2938, -0.2614,  ...,  0.0189, -0.1409, -0.0500]],\n",
       "\n",
       "         [[ 0.0245, -0.1403, -0.2710,  ...,  0.3971,  0.6188,  0.1263],\n",
       "          [-0.2164, -0.5576, -0.6970,  ..., -0.0179,  0.2713, -0.3614],\n",
       "          [-0.0814, -0.2470, -0.4756,  ...,  0.1182,  0.1159, -0.2434],\n",
       "          ...,\n",
       "          [ 0.3127, -0.1926, -0.0810,  ...,  0.0228,  0.2105,  0.0279],\n",
       "          [ 0.4137,  0.0812, -0.0063,  ...,  0.6189,  0.3797,  0.0574],\n",
       "          [ 0.1254,  0.5517,  0.4892,  ...,  0.3102,  0.2834,  0.3236]],\n",
       "\n",
       "         [[ 0.0989,  0.1037, -0.0128,  ...,  0.0549, -0.0072,  0.5157],\n",
       "          [-0.3439, -0.0932,  0.1105,  ...,  0.6428,  0.6733,  0.7803],\n",
       "          [-0.4283, -0.4534, -0.3824,  ...,  0.6729,  0.7587,  0.8116],\n",
       "          ...,\n",
       "          [-0.2336, -0.2690, -0.2411,  ..., -0.2779, -0.4670,  0.1972],\n",
       "          [-0.4601, -0.3481, -0.3770,  ..., -0.2074, -0.2819,  0.3155],\n",
       "          [-0.3233, -0.1578, -0.2165,  ..., -0.1194, -0.2079,  0.2429]]]],\n",
       "       device='cuda:0', grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.0123,  8.9785,  8.7240,  9.2353,  9.1543,  8.4913, 10.4498,  5.6645,\n",
       "         2.7424,  6.9139,  9.8619,  9.5497,  9.0830,  4.5111, 11.0013,  9.7003,\n",
       "        17.7209,  8.9814,  7.4079, 11.5696,  7.1058,  6.7530,  7.7741,  9.8422,\n",
       "         6.7167,  6.9624,  4.7837,  9.2906,  7.0158,  0.1005, 15.7438,  0.6373,\n",
       "        14.9711, 11.9976,  9.3914, 17.8930, 12.8195,  7.6045,  0.3736, 10.7709,\n",
       "        12.5249, 11.2561,  7.4585,  0.9595,  9.3194,  7.8345,  3.3790,  3.6517,\n",
       "        16.4372,  0.3863,  8.6766,  9.7391,  6.0877,  9.7325, 15.5497,  8.2449,\n",
       "        12.2397,  9.2026, 10.8324, 10.1944,  0.1756,  5.5703,  7.8814,  8.4478],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"architecture\": \"big_resnet\",\n",
    "#         \"conditional_strategy\": \"ProjGAN\",\n",
    "#         \"pos_collected_numerator\": false,\n",
    "#         \"hypersphere_dim\": \"N/A\",\n",
    "#         \"nonlinear_embed\": false,\n",
    "#         \"normalize_embed\": false,\n",
    "#         \"g_spectral_norm\": true,\n",
    "#         \"d_spectral_norm\": true,\n",
    "#         \"activation_fn\": \"ReLU\",\n",
    "#         \"attention\": true,\n",
    "#         \"attention_after_nth_gen_block\": 2,\n",
    "#         \"attention_after_nth_dis_block\": 1,\n",
    "#         \"z_dim\": 80,\n",
    "#         \"shared_dim\": 128,\n",
    "#         \"g_conv_dim\": 96,\n",
    "#         \"d_conv_dim\": 96,\n",
    "#         \"G_depth\":\"N/A\",\n",
    "#         \"D_depth\":\"N/A\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AdversarialSampleDetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
